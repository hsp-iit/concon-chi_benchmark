{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) 2024 Istituto Italiano di Tecnologia.  All rights reserved.\n",
    "#\n",
    "# This work is licensed under the LICENSE file \n",
    "# located at the root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "%load_ext autoreload\n",
    "\n",
    "from importlib import import_module\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from vlpers.utils.evaluation import get_ranks, mAP, mAP_at, mRR, recall_at\n",
    "import vlpers.utils.logging as logging\n",
    "from vlpers.utils.logging import logger\n",
    "from vlpers.utils import misc\n",
    "from pprint import pformat\n",
    "\n",
    "os.chdir('..')\n",
    "os.chdir = lambda x: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.retrieval import Config as cfg\n",
    "from configs.methods.baselines.image_text import Method\n",
    "\n",
    "dataset = 'conconchi'\n",
    "\n",
    "cfg.Data = import_module(f'configs.datasets.{dataset}').Data\n",
    "cfg.Method = Method\n",
    "\n",
    "cfg.Logging.log_dir = Path('logs/weighted_average')\n",
    "cfg.Logging.exp_dir = dataset\n",
    "\n",
    "logger.setLevel(10)\n",
    "misc.set_reproducibility()\n",
    "    \n",
    "exp_dir = (cfg.Logging.log_dir / cfg.Logging.exp_dir)\n",
    "exp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cfg.Logging.exp_dir = Path(exp_dir)\n",
    "logging.enable_file_handler(exp_dir / 'logs.txt')\n",
    "\n",
    "misc.save_config(cfg.Logging.exp_dir, cfg)\n",
    "misc.git_check_workspace(make_patch=cfg.Git.make_patch, path=exp_dir.resolve())\n",
    "logger.info(f'\\n{pformat(cfg.to_dict())}\\n')\n",
    "\n",
    "method = cfg.Method()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn the new concepts embeddings\n",
    "concept_dataset = cfg.Data.LearnDS(image_transform=method.image_transform, text_transform=method.text_transform)\n",
    "if not cfg.Method.load_concepts:\n",
    "    method.set_mode(cfg.Method.Mode.LEARNING)\n",
    "    for batch in concept_dataset.dl:\n",
    "        images, _, concepts = batch \n",
    "        method.learn_concepts(images, concepts)\n",
    "        \n",
    "    if cfg.Logging.log_dir and cfg.Logging.save_concepts:\n",
    "        method.save_concepts(cfg.Logging.exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate image pool\n",
    "method.set_mode(cfg.Method.Mode.TESTING)\n",
    "image_dataset = cfg.Data.ImagePoolDS(image_transform=method.image_transform, text_transform=method.text_transform)\n",
    "if not cfg.Method.load_image_pool:\n",
    "    for batch in image_dataset.dl:\n",
    "        images, *_ = batch \n",
    "        method.add_image_pool(images)\n",
    "    if cfg.Logging.log_dir and cfg.Logging.save_image_pool:\n",
    "        method.save_image_pool(cfg.Logging.exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_avg = defaultdict(lambda:[])\n",
    "\n",
    "for a in range(11):\n",
    "    method.alpha = (a / 10)\n",
    "    \n",
    "        # Retrieve images\n",
    "    eval_dataset = cfg.Data.EvalDS(image_transform=method.image_transform, text_transform=method.text_transform)\n",
    "    results = defaultdict(lambda:[])\n",
    "    for batch in eval_dataset.dl:\n",
    "        gt, labels, concepts = batch\n",
    "\n",
    "        scores = method.retrieve(descriptions=labels, concepts=concepts)\n",
    "        \n",
    "        # Log Metrics and log\n",
    "        ranks, rank_ids = get_ranks(scores, gt)\n",
    "        \n",
    "        ranks = [[rank for rank in gt_ranks if rank != -1] for gt_ranks in ranks.tolist()]\n",
    "        rank_ids = [[eval_dataset.map.reset_index().set_index(['ID_GTS']).loc[id].item() for id in gt_ids if id != -1] for gt_ids in rank_ids.tolist()]\n",
    "        \n",
    "        results['Ranks'] += ranks\n",
    "        results['Rank_ids'] += rank_ids\n",
    "        results['mRR'] += mRR(scores, gt, avg=False).tolist()\n",
    "        results['mAP'] += mAP(scores, gt, avg=False).tolist()\n",
    "        for k in [1, 5, 10]:\n",
    "            results[f'R@{k}'] += recall_at(scores, gt, k=k, avg=False).tolist()\n",
    "            results[f'mAP@{k}'] += mAP_at(scores, gt, k=k, avg=False).tolist()\n",
    "      \n",
    "    # Save Metrics \n",
    "    labels = eval_dataset.df\n",
    "    results = pd.DataFrame.from_dict(results)\n",
    "    results = pd.concat([labels, results], axis=1)\n",
    "\n",
    "    weighted_avg['alpha'] += [method.alpha]\n",
    "    weighted_avg['mAP'] += [results[[\"mAP\"]].mean().item()]\n",
    "    \n",
    "    logger.info(f'alpha: {method.alpha} mAP: {results[[\"mAP\"]].mean().item():.2f}')\n",
    "    \n",
    "misc.save_results(cfg.Logging.exp_dir, pd.DataFrame.from_dict(weighted_avg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "methods = {}\n",
    "for p in Path('logs/weighted_average').glob('*'):\n",
    "    methods[p.name] = pd.read_csv(p / 'results.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = ['#008fd5', '#fc4f30', '#e5ae38', '#8b8b8b', '#810f7c']\n",
    "\n",
    "def plot_methods(methods, contains='', name_list=None):\n",
    "    if isinstance(name_list, str):\n",
    "        name_list = [name_list]\n",
    "    \n",
    "    i = 0\n",
    "    for name in methods:\n",
    "        if name_list and name not in name_list:\n",
    "            continue \n",
    "        \n",
    "        if contains not in name:\n",
    "            continue\n",
    "        \n",
    "        df = methods[name]\n",
    "        plt.plot(df['alpha'], df['mAP'] * 100, label=name, color=color[i])\n",
    "        i += 1\n",
    "\n",
    "    # Add labels and legend\n",
    "    plt.xticks([n/10 for n in range(11)])\n",
    "    plt.xlim(-0.05, 1.35)\n",
    "    plt.xlabel('Î±')\n",
    "    plt.ylabel('mAP [%]')\n",
    "    plt.legend(loc=2)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.savefig('weighted.svg')  \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "sns.set_style('whitegrid')\n",
    "plot_methods(methods, name_list=['circo', 'conconchi', 'cirr', 'deepfashion', 'fashioniq'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
