diff --git a/examples/dreambooth/train_dreambooth.py b/src/diffusers/train_dreambooth.py
similarity index 96%
rename from examples/dreambooth/train_dreambooth.py
rename to src/diffusers/train_dreambooth.py
index 797cfbd0..a8816d31 100644
--- a/examples/dreambooth/train_dreambooth.py
+++ b/src/diffusers/train_dreambooth.py
@@ -1,7 +1,13 @@
-#!/usr/bin/env python
+# ---------------------------------------------------------------
+# This file has been modified from the file in the following repository:
+# https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth.py
+# See below for the original license.
+# ---------------------------------------------------------------
+# 
+# #!/usr/bin/env python
 # coding=utf-8
 # Copyright 2023 The HuggingFace Inc. team. All rights reserved.
-#
+# 
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
@@ -49,6 +55,7 @@ from diffusers import (
     DPMSolverMultistepScheduler,
     StableDiffusionPipeline,
     UNet2DConditionModel,
+    DDIMScheduler
 )
 from diffusers.optimization import get_scheduler
 from diffusers.utils import check_min_version, is_wandb_available
@@ -161,26 +168,26 @@ def log_validation(
     if args.validation_images is None:
         for _ in range(args.num_validation_images):
             with torch.autocast("cuda"):
-                image = pipeline(**pipeline_args, num_inference_steps=25, generator=generator).images[0]
-            images.append(image)
+                image = pipeline(**pipeline_args, num_inference_steps=100, guidance_scale=7.5, generator=generator).images
+            images.extend(image)
     else:
         for image in args.validation_images:
             image = Image.open(image)
             image = pipeline(**pipeline_args, image=image, generator=generator).images[0]
             images.append(image)
 
-    for tracker in accelerator.trackers:
-        if tracker.name == "tensorboard":
-            np_images = np.stack([np.asarray(img) for img in images])
-            tracker.writer.add_images("validation", np_images, epoch, dataformats="NHWC")
-        if tracker.name == "wandb":
-            tracker.log(
-                {
-                    "validation": [
-                        wandb.Image(image, caption=f"{i}: {args.validation_prompt}") for i, image in enumerate(images)
-                    ]
-                }
-            )
+    # for tracker in accelerator.trackers:
+    #     if tracker.name == "tensorboard":
+    #         np_images = np.stack([np.asarray(img) for img in images])
+    #         tracker.writer.add_images("validation", np_images, epoch, dataformats="NHWC")
+    #     if tracker.name == "wandb":
+    #         tracker.log(
+    #             {
+    #                 "validation": [
+    #                     wandb.Image(image, caption=f"{i}: {args.validation_prompt}") for i, image in enumerate(images)
+    #                 ]
+    #             }
+    #         )
 
     del pipeline
     torch.cuda.empty_cache()
@@ -218,7 +225,7 @@ def parse_args(input_args=None):
         "--pretrained_model_name_or_path",
         type=str,
         default=None,
-        required=True,
+        required=False,
         help="Path to pretrained model or model identifier from huggingface.co/models.",
     )
     parser.add_argument(
@@ -241,7 +248,7 @@ def parse_args(input_args=None):
         "--instance_data_dir",
         type=str,
         default=None,
-        required=True,
+        required=False,
         help="A folder containing the training data of instance images.",
     )
     parser.add_argument(
@@ -255,7 +262,7 @@ def parse_args(input_args=None):
         "--instance_prompt",
         type=str,
         default=None,
-        required=True,
+        required=False,
         help="The prompt with identifier specifying the instance",
     )
     parser.add_argument(
@@ -448,7 +455,7 @@ def parse_args(input_args=None):
     )
     parser.add_argument(
         "--validation_prompt",
-        type=str,
+        type=list,
         default=None,
         help="A prompt that is used during validation to verify that the model is learning.",
     )
@@ -883,7 +890,7 @@ def main(args):
     text_encoder_cls = import_model_class_from_model_name_or_path(args.pretrained_model_name_or_path, args.revision)
 
     # Load scheduler and models
-    noise_scheduler = DDPMScheduler.from_pretrained(args.pretrained_model_name_or_path, subfolder="scheduler")
+    noise_scheduler = DDIMScheduler.from_pretrained(args.pretrained_model_name_or_path, subfolder="scheduler")
     text_encoder = text_encoder_cls.from_pretrained(
         args.pretrained_model_name_or_path, subfolder="text_encoder", revision=args.revision
     )
@@ -1115,8 +1122,8 @@ def main(args):
 
     # We need to initialize the trackers we use, and also store our configuration.
     # The trackers initializes automatically on the main process.
-    if accelerator.is_main_process:
-        accelerator.init_trackers("dreambooth", config=vars(args))
+    # if accelerator.is_main_process:
+    #     accelerator.init_trackers("dreambooth", config=vars(args))
 
     # Train!
     total_batch_size = args.train_batch_size * accelerator.num_processes * args.gradient_accumulation_steps
@@ -1309,10 +1316,15 @@ def main(args):
                             validation_prompt_encoder_hidden_states,
                             validation_prompt_negative_prompt_embeds,
                         )
+                        
+                        print(args.output_dir + f"/val{global_step}")
+                        os.mkdir(args.output_dir + f"/val{global_step}")
+                        for i, image in enumerate(images):
+                            image.save(os.path.join(args.output_dir + f"/val{global_step}", f"image_{i}.png"))
 
             logs = {"loss": loss.detach().item(), "lr": lr_scheduler.get_last_lr()[0]}
             progress_bar.set_postfix(**logs)
-            accelerator.log(logs, step=global_step)
+            # accelerator.log(logs, step=global_step)
 
             if global_step >= args.max_train_steps:
                 break
@@ -1367,7 +1379,7 @@ def main(args):
                 ignore_patterns=["step_*", "epoch_*"],
             )
 
-    accelerator.end_training()
+    # accelerator.end_training()
 
 
 if __name__ == "__main__":
